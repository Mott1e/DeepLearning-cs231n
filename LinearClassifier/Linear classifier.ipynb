{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1.2 - Линейный классификатор (Linear classifier)\n",
    "\n",
    "В этом задании мы реализуем другую модель машинного обучения - линейный классификатор. Линейный классификатор подбирает для каждого класса веса, на которые нужно умножить значение каждого признака и потом сложить вместе.\n",
    "Тот класс, у которого эта сумма больше, и является предсказанием модели.\n",
    "\n",
    "В этом задании вы:\n",
    "- потренируетесь считать градиенты различных многомерных функций\n",
    "- реализуете подсчет градиентов через линейную модель и функцию потерь softmax\n",
    "- реализуете процесс тренировки линейного классификатора\n",
    "- подберете параметры тренировки на практике\n",
    "\n",
    "На всякий случай, еще раз ссылка на туториал по numpy:  \n",
    "http://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_gradient\n",
    "from metrics import multiclass_accuracy \n",
    "import linear_classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, первым делом загружаем данные\n",
    "\n",
    "Мы будем использовать все тот же SVHN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_linear_classifier(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    # Add another channel with ones as a bias term\n",
    "    train_flat_with_ones = np.hstack([train_flat, np.ones((train_X.shape[0], 1))])\n",
    "    test_flat_with_ones = np.hstack([test_flat, np.ones((test_X.shape[0], 1))])    \n",
    "    return train_flat_with_ones, test_flat_with_ones\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_linear_classifier(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Играемся с градиентами!\n",
    "\n",
    "В этом курсе мы будем писать много функций, которые вычисляют градиенты аналитическим методом.\n",
    "\n",
    "Все функции, в которых мы будем вычислять градиенты, будут написаны по одной и той же схеме.  \n",
    "Они будут получать на вход точку, где нужно вычислить значение и градиент функции, а на выходе будут выдавать кортеж (tuple) из двух значений - собственно значения функции в этой точке (всегда одно число) и аналитического значения градиента в той же точке (той же размерности, что и вход).\n",
    "```\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    Computes function and analytic gradient at x\n",
    "    \n",
    "    x: np array of float, input to the function\n",
    "    \n",
    "    Returns:\n",
    "    value: float, value of the function \n",
    "    grad: np array of float, same shape as x\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \n",
    "    return value, grad\n",
    "```\n",
    "\n",
    "Необходимым инструментом во время реализации кода, вычисляющего градиенты, является функция его проверки. Эта функция вычисляет градиент численным методом и сверяет результат с градиентом, вычисленным аналитическим методом.\n",
    "\n",
    "Мы начнем с того, чтобы реализовать вычисление численного градиента (numeric gradient) в функции `check_gradient` в `gradient_check.py`. Эта функция будет принимать на вход функции формата, заданного выше, использовать значение `value` для вычисления численного градиента и сравнит его с аналитическим - они должны сходиться.\n",
    "\n",
    "Напишите часть функции, которая вычисляет градиент с помощью численной производной для каждой координаты. Для вычисления производной используйте так называемую two-point formula (https://en.wikipedia.org/wiki/Numerical_differentiation):\n",
    "\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/22fc2c0a66c63560a349604f8b6b39221566236d)\n",
    "\n",
    "Все функции приведенные в следующей клетке должны проходить gradient check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the functions below should pass the gradient check\n",
    "\n",
    "def square(x):\n",
    "    return x*x, 2*x\n",
    "\n",
    "check_gradient(square, np.array([3.0]))\n",
    "\n",
    "def array_sum(x):\n",
    "    assert x.shape == (2,), x.shape\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_sum, np.array([3.0, 2.0]))\n",
    "\n",
    "def array_2d_sum(x):\n",
    "    assert x.shape == (2,2)\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_2d_sum, np.array([[3.0, 2.0], [1.0, 0.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Начинаем писать свои функции, считающие аналитический градиент\n",
    "\n",
    "Теперь реализуем функцию softmax, которая получает на вход оценки для каждого класса и преобразует их в вероятности от 0 до 1:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3)\n",
    "\n",
    "**Важно:** Практический аспект вычисления этой функции заключается в том, что в ней участвует вычисление экспоненты от потенциально очень больших чисел - это может привести к очень большим значениям в числителе и знаменателе за пределами диапазона float.\n",
    "\n",
    "К счастью, у этой проблемы есть простое решение -- перед вычислением softmax вычесть из всех оценок максимальное значение среди всех оценок:\n",
    "```\n",
    "predictions -= np.max(predictions)\n",
    "```\n",
    "(подробнее здесь - http://cs231n.github.io/linear-classify/#softmax, секция `Practical issues: Numeric stability`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e+00 8.19401262e-40 1.92874985e-22]\n"
     ]
    }
   ],
   "source": [
    "probs = linear_classifer.softmax(np.array([-10, 0, 10]))\n",
    "\n",
    "# Make sure it works for big numbers too!\n",
    "probs = linear_classifer.softmax(np.array([100, 10, 50]))\n",
    "assert np.isclose(probs[0], 1.0)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме этого, мы реализуем cross-entropy loss, которую мы будем использовать как функцию ошибки (error function).\n",
    "В общем виде cross-entropy определена следующим образом:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/0cb6da032ab424eefdca0884cd4113fe578f4293)\n",
    "\n",
    "где x - все классы, p(x) - истинная вероятность принадлежности сэмпла классу x, а q(x) - вероятность принадлежности классу x, предсказанная моделью.  \n",
    "В нашем случае сэмпл принадлежит только одному классу, индекс которого передается функции. Для него p(x) равна 1, а для остальных классов - 0. \n",
    "\n",
    "Это позволяет реализовать функцию проще!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.006760443547122"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = linear_classifer.softmax(np.array([-5, 0, 5]))\n",
    "linear_classifer.cross_entropy_loss(probs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того как мы реализовали сами функции, мы можем реализовать градиент.\n",
    "\n",
    "Оказывается, что вычисление градиента становится гораздо проще, если объединить эти функции в одну, которая сначала вычисляет вероятности через softmax, а потом использует их для вычисления функции ошибки через cross-entropy loss.\n",
    "\n",
    "Эта функция `softmax_with_cross_entropy` будет возвращает и значение ошибки, и градиент по входным параметрам. Мы проверим корректность реализации с помощью `check_gradient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "loss: 1.551444713932051 | grad: [ 0.57611688 -0.78805844  0.21194156]\n"
     ]
    }
   ],
   "source": [
    "loss, grad = linear_classifer.softmax_with_cross_entropy(np.array([1, 0, 0]), 1)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, 1), np.array([1, 0, 0], float))\n",
    "print(f'loss: {loss} | grad: {grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метода тренировки мы будем использовать стохастический градиентный спуск (stochastic gradient descent или SGD), который работает с батчами сэмплов. \n",
    "\n",
    "Поэтому все наши фукнции будут получать не один пример, а батч, то есть входом будет не вектор из `num_classes` оценок, а матрица размерности `batch_size, num_classes`. Индекс примера в батче всегда будет первым измерением.\n",
    "\n",
    "Следующий шаг - переписать наши функции так, чтобы они поддерживали батчи.\n",
    "\n",
    "Финальное значение функции ошибки должно остаться числом, и оно равно среднему значению ошибки среди всех примеров в батче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "# Test batch_size = 1\n",
    "num_classes = 4\n",
    "batch_size = 1\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(float)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Test batch_size = 3\n",
    "num_classes = 4\n",
    "batch_size = 3\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(float)\n",
    "target_index = np.random.randint(0, num_classes, size=batch_size).astype(int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наконец, реализуем сам линейный классификатор!\n",
    "\n",
    "softmax и cross-entropy получают на вход оценки, которые выдает линейный классификатор.\n",
    "\n",
    "Он делает это очень просто: для каждого класса есть набор весов, на которые надо умножить пиксели картинки и сложить. Получившееся число и является оценкой класса, идущей на вход softmax.\n",
    "\n",
    "Таким образом, линейный классификатор можно представить как умножение вектора с пикселями на матрицу W размера `num_features, num_classes`. Такой подход легко расширяется на случай батча векторов с пикселями X размера `batch_size, num_features`:\n",
    "\n",
    "`predictions = X * W`, где `*` - матричное умножение.\n",
    "\n",
    "Реализуйте функцию подсчета линейного классификатора и градиентов по весам `linear_softmax` в файле `linear_classifer.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_classes = 2\n",
    "num_features = 3\n",
    "np.random.seed(42)\n",
    "W = np.random.randint(-1, 3, size=(num_features, num_classes)).astype(float)\n",
    "X = np.random.randint(-1, 3, size=(batch_size, num_features)).astype(float)\n",
    "target_index = np.ones(batch_size, dtype=int)\n",
    "\n",
    "loss, dW = linear_classifer.linear_softmax(X, W, target_index)\n",
    "check_gradient(lambda w: linear_classifer.linear_softmax(X, w, target_index), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### И теперь регуляризация\n",
    "\n",
    "Мы будем использовать L2 regularization для весов как часть общей функции ошибки.\n",
    "\n",
    "Напомним, L2 regularization определяется как\n",
    "\n",
    "l2_reg_loss = regularization_strength * sum<sub>ij</sub> W[i, j]<sup>2</sup>\n",
    "\n",
    "Реализуйте функцию для его вычисления и вычисления соотвествующих градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_classifer.l2_regularization(W, 0.01)\n",
    "check_gradient(lambda w: linear_classifer.l2_regularization(w, 0.01), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировка!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиенты в порядке, реализуем процесс тренировки!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 2.302190\n"
     ]
    }
   ],
   "source": [
    "classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "loss_history = classifier.fit(train_X, train_y, epochs=10, learning_rate=0.001, batch_size=300, reg=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15da11a8d00>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's look at the loss history!\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.127\n",
      "Epoch 0, loss: 2.300957\n",
      "Epoch 50, loss: 2.301119\n",
      "Accuracy after training for 100 epochs:  0.121\n"
     ]
    }
   ],
   "source": [
    "# Let's check how it performs on validation set\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# Now, let's train more and see if it performs better\n",
    "classifier.fit(train_X, train_y, epochs=100, learning_rate=1e-3, batch_size=300, reg=1e1)\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy after training for 100 epochs: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как и раньше, используем кросс-валидацию для подбора гиперпараметтов.\n",
    "\n",
    "В этот раз, чтобы тренировка занимала разумное время, мы будем использовать только одно разделение на тренировочные (training) и проверочные (validation) данные.\n",
    "\n",
    "Теперь нам нужно подобрать не один, а два гиперпараметра! Не ограничивайте себя изначальными значениями в коде.  \n",
    "Добейтесь точности более чем **20%** на проверочных данных (validation data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 2.262381\n",
      "Epoch 50, loss: 2.119001\n",
      "Epoch 100, loss: 2.061527\n",
      "Epoch 150, loss: 2.101476\n",
      "Epoch 200, loss: 2.025301\n",
      "Epoch 250, loss: 2.104854\n",
      "Epoch 300, loss: 2.106579\n",
      "Accuracy: 0.234 | learning_rate: 0.15 | reg: 0.001\n",
      "best accuracy: 0.234 with learning rate: 0.15 | best reg: 0.001\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 350\n",
    "batch_size = 300\n",
    "\n",
    "learning_rates = [0.15]\n",
    "reg_strengths = [0.001]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "best_lr = 0\n",
    "best_reg = 0\n",
    "\n",
    "l_class = linear_classifer.LinearSoftmaxClassifier()\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for reg in reg_strengths:\n",
    "        l_class.W = None\n",
    "        l_class.fit(train_X, train_y, batch_size=batch_size, learning_rate=lr, reg=reg, epochs=num_epochs)\n",
    "        predict = l_class.predict(val_X)\n",
    "        accuracy = multiclass_accuracy(predict, val_y)\n",
    "        print(f'Accuracy: {accuracy} | learning_rate: {lr} | reg: {reg}')\n",
    "\n",
    "        if accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = accuracy\n",
    "            best_classifier = l_class\n",
    "            best_reg = reg\n",
    "            best_lr = lr\n",
    "\n",
    "print(f'best accuracy: {best_val_accuracy} with learning rate: {best_lr} | best reg: {best_reg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Какой же точности мы добились на тестовых данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear softmax classifier test set accuracy: 0.214000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Linear softmax classifier test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
